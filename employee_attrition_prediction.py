# -*- coding: utf-8 -*-
"""Employee Attrition Prediction

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JUemZYagtbKPlYW-FwHLC6ai-CY7vcBO

#### **NECESSARY IMPORTS**
"""

# Import necessary libraries

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px

from sklearn import preprocessing
from imblearn.under_sampling import RandomUnderSampler
from sklearn.feature_selection import SelectKBest, f_classif, RFE
from sklearn.decomposition import PCA

from sklearn.linear_model import LogisticRegression
from lightgbm import LGBMClassifier
from sklearn.tree import DecisionTreeClassifier
from xgboost import XGBClassifier
from sklearn.ensemble import RandomForestClassifier

from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, classification_report, precision_recall_curve, roc_curve, auc, log_loss)
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder, OneHotEncoder, StandardScaler
from sklearn.feature_selection import RFECV
from sklearn.feature_selection import RFE

# Ignore warnings for simplicity
import warnings
warnings.simplefilter(action='ignore')

"""#### **DATA LOADING**

"""

# Loading the dataset from a CSV file into a DataFrame
df = pd.read_csv('/content/WA_Fn-UseC_-HR-Employee-Attrition.csv')

# Displaying the first few rows of the DataFrame to get an overview of the data
# df.head()

# Retrieves the dimensions of the DataFrame (number of rows and columns)
num_rows, num_columns = df.shape

# Prints out the number of rows and columns in the DataFrame
# print(f"The dataset has {num_rows} rows and {num_columns} columns.")

"""#### **DATA CLEANING AND VISUALIZATION**

**DATA CLEANING**
"""

# Data Cleaning: Dropping unnecessary columns
df = df.drop(['EmployeeCount',
                 'EmployeeNumber',
                 'Over18',
                  'StandardHours'],axis = 1)

# Displaying the remaining column names in the DataFrame
# df.columns

# Checking for missing values
missing_values = df.isnull().sum()

# Print the number of missing values in each column
# print(missing_values)

"""**VISUALIZATION**"""

# Creating a pie chart to visualize the distribution of the target variable 'Attrition'
fig = px.pie(df, names = 'Attrition', title = 'Target Variable: Attrition', template = 'plotly_dark')

# Updating the pie chart with custom settings
fig.update_traces(rotation=90, pull = [0.3], textinfo = "percent+label")

# Displaying the pie chart
# fig.show()

def categorical_plot(df, i, column):
    # Calculate the percentage of attrition for each category in column 'i'
    df_percent = df.groupby([i])[column].value_counts(normalize=True).mul(100).rename('percentage').reset_index()

    # Create a stacked bar plot using Plotly Express
    fig = px.bar(
        df_percent,
        x=i,
        y='percentage',
        color=column,
        barmode='stack',
        text=df_percent['percentage'].apply(lambda x: f'{x:.0f}%'),
        template='plotly_dark',
        title=f'Attrition x {i}'
    )

    # Update layout for better readability
    fig.update_layout(
        xaxis_title=i,
        yaxis_title="Percentage",
        yaxis_tickformat=",.%",
        bargap=0.2
    )

    # Display the plot
    # fig.show()

# Creating visualizations for different categorical variables with respect to 'Attrition'
categorical_plot(df,'BusinessTravel', 'Attrition')
categorical_plot(df,'Department','Attrition')
categorical_plot(df,'Education', 'Attrition')
categorical_plot(df,'EnvironmentSatisfaction', 'Attrition')
categorical_plot(df,'EducationField', 'Attrition')
categorical_plot(df,'Gender', 'Attrition')
categorical_plot(df,'JobInvolvement', 'Attrition')
categorical_plot(df,'JobSatisfaction', 'Attrition')
categorical_plot(df,'WorkLifeBalance', 'Attrition')
categorical_plot(df,'PerformanceRating', 'Attrition')
categorical_plot(df,'JobRole', 'Attrition')
categorical_plot(df,'MaritalStatus', 'Attrition')
categorical_plot(df,'RelationshipSatisfaction', 'Attrition')
categorical_plot(df,'OverTime', 'Attrition')

"""#### **DATA PREPROCESSING**

**HANDLING IMBLANCE**
"""

# Splitting features and target variable
X = df.drop('Attrition', axis = 1)
y = df.Attrition

# Handling class imbalance using RandomUnderSampler
undersampler = RandomUnderSampler(random_state=42)
X_resampled, y_resampled = undersampler.fit_resample(X, y)

# Splitting the resampled data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X_resampled,y_resampled,test_size = 0.3)

# Print the sizes of the training and test datasets
# print('X train size: ', len(X_train))
# print('X test size: ', len(X_test))
# print('y train size: ', len(y_train))
# print('y test size: ', len(y_test))

"""**ENCODING**

**ORDINAL ENCODING**
"""

# Encoding categorical variables using OrdinalEncoder
OE = OrdinalEncoder()

# List of categorical columns to be encoded
columns_OE = ['BusinessTravel', 'Education', 'EnvironmentSatisfaction', 'JobInvolvement',
             'JobSatisfaction','WorkLifeBalance','PerformanceRating','RelationshipSatisfaction']

# Fit the OrdinalEncoder on the training data and transform these categorical columns
X_train[columns_OE] = OE.fit_transform(X_train[columns_OE])

# Transform the same categorical columns in the test data using the fitted encoder
X_test[columns_OE] = OE.transform(X_test[columns_OE])

# Display the transformed training data
# X_train

"""**BINARY ENCODING**"""

# Transforming bicategoric variables into binary values
X_train['OverTime'].replace({'Yes': 1, 'No': 0}, inplace=True)
X_test['OverTime'].replace({'Yes': 1, 'No': 0}, inplace=True)

# Convert the 'Gender' column values from 'Male'/'Female' to 1/0
X_train['Gender'].replace({'Male': 1, 'Female': 0}, inplace=True)
X_test['Gender'].replace({'Male': 1, 'Female': 0}, inplace=True)

"""**ONE-HOT ENCODING**"""

# Define columns to one-hot encode
columns_OHE = ['Department', 'EducationField', 'JobRole', 'MaritalStatus']

# Initialize OneHotEncoder with handle_unknown='ignore' and sparse=False
OHE = OneHotEncoder(handle_unknown='ignore', sparse_output=False)

# Fit the encoder on X_train and transform it into a DataFrame
X_train_ohe = pd.DataFrame(OHE.fit_transform(X_train[columns_OHE]))

# Transform X_test using the fitted encoder
X_test_ohe = pd.DataFrame(OHE.transform(X_test[columns_OHE]))

# Retrieve the feature names generated by one-hot encodin
feature_names = OHE.get_feature_names_out(columns_OHE)

# Assign the feature names to the columns of the encoded DataFrames
X_train_ohe.columns = feature_names
X_test_ohe.columns = feature_names

# Restore the original index to the encoded DataFrames
X_train_ohe.index = X_train.index
X_test_ohe.index = X_test.index

# Drop the original categorical columns from X_train and X_test
num_X_train = X_train.drop([col for col in X_train.columns if X_train[col].dtype == "object"], axis = 1)
num_X_test = X_test.drop([col for col in X_test.columns if X_test[col].dtype == "object"], axis = 1)

# Concatenate the numerical features with the one-hot encoded features
X_train = pd.concat([num_X_train,X_train_ohe ],axis = 1)
X_test = pd.concat([num_X_test, X_test_ohe], axis = 1)

"""**ENCODING TARGET VARIABLE**"""

# Encoding target variable
y_train.replace({'No': 0, 'Yes': 1}, inplace=True)
y_test.replace({'No': 0, 'Yes': 1}, inplace=True)

# Converting column names to strings
X_train.columns = X_train.columns.astype(str)
X_test.columns = X_test.columns.astype(str)

"""#### **FEATURE SELECTION**"""

# Feature selection function
def feature_selection(data, target, num_features, method):
    # Separate the target variable
    X = data.drop(columns=[target])
    y = data[target]

    selected_features = []

    # Select features based on the specified method
    if method == 'Univariate_Selection':
        univariate_selector = SelectKBest(score_func=f_classif, k=num_features)
        univariate_selector.fit(X, y)
        selected_features = X.columns[univariate_selector.get_support()].tolist()

    # Recursive Feature Elimination (RFE) with RandomForestClassifier to select the top 'num_features' features
    elif method == 'RFE':
        model = RandomForestClassifier()
        rfe_selector = RFE(model, n_features_to_select=num_features, step=1)
        rfe_selector.fit(X, y)
        selected_features = X.columns[rfe_selector.get_support()].tolist()

    # Principal Component Analysis (PCA) to reduce the dimensionality to 'num_features'
    elif method == 'PCA':
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        pca = PCA(n_components=num_features)
        pca.fit(X_scaled)
        selected_features = ['PCA_' + str(i) for i in range(num_features)]

    # Feature importance using RandomForestClassifier to identify the top 'num_features' features
    elif method == 'Feature_Importance':
        model = RandomForestClassifier()
        model.fit(X, y)
        importance = model.feature_importances_
        importance_indices = np.argsort(importance)[-num_features:]
        selected_features = X.columns[importance_indices].tolist()

    # Feature selection based on correlation with the target variable
    elif method == 'Correlation':
        # Compute the correlation matrix
        correlation_matrix = data.corr()
        # Get the absolute values of the correlation with the target variable
        correlation_with_target = correlation_matrix[target].abs()
        # Drop the target variable itself
        correlation_with_target = correlation_with_target.drop(target)
        # Get the top 'num_features' features
        selected_features = correlation_with_target.sort_values(ascending=False).head(num_features).index.tolist()

    else:
        # Raise an error if the specified method is invalid
        raise ValueError("Invalid method. Choose from 'Univariate_Selection', 'RFE', 'PCA', 'Feature_Importance', or 'Correlation'")

    return selected_features

# Applying feature selection
X_train_d = X_train.copy()
X_train_d['Attrition'] = y_train

# Select the top 20 features based on feature importance
selected_features = feature_selection(X_train_d, 'Attrition', 20, 'Feature_Importance')

# Subset the training and test data to include only the selected features
# X_train_selected = X_train[selected_features]
# X_test_selected = X_test[selected_features]

"""#### **MODEL TRAINING AND EVALUATION**"""

# Creating a function for predictions
def predict(model, X_train, y_train, X_test, y_test):
   # Train the model using the training data
    model.fit(X_train, y_train)

    # Predict the target values for the test data
    y_predict = model.predict(X_test)

    # Calculate and print evaluation metrics
    print('Accuracy: %.2f%%' % (accuracy_score(y_test, y_predict) * 100 ))
    print('Precision: %.2f%%' % (precision_score(y_test, y_predict) * 100))
    print('Recall: %.2f%%' % (recall_score(y_test, y_predict) * 100))
    print('F1_Score: %.2f%%' % (f1_score(y_test, y_predict) * 100))

    # Generate and plot the confusion matrix
    confusion_matrix_model = confusion_matrix(y_test, y_predict)
    plt.figure(figsize=(4,3))
    ax = plt.subplot()
    sns.heatmap(confusion_matrix_model, annot=True, fmt='g', ax = ax)
    ax.set_xlabel('Predicted Label')
    ax.set_ylabel('Actual Label')
    ax.xaxis.set_ticklabels(['0','1'])
    ax.yaxis.set_ticklabels(['0','1'])

# Initializing models
logreg = LogisticRegression()
randomforest = RandomForestClassifier()
xgboost =  XGBClassifier()
lgbm_classifier = LGBMClassifier()
decisiontree = DecisionTreeClassifier()

# Predicting and evaluating with each model

# print("Logistic Regression:")
# predict(logreg, X_train_selected, y_train, X_test_selected, y_test)

# print("\nRandom Forest:")
# predict(randomforest, X_train_selected, y_train, X_test_selected, y_test)

# print("\nXGBoost:")
# predict(xgboost, X_train_selected, y_train, X_test_selected, y_test)

# print("\nLightGBM:")
# predict(lgbm_classifier, X_train_selected, y_train, X_test_selected, y_test)

# print("\nDecision Tree:")
# predict(decisiontree, X_train_selected, y_train, X_test_selected, y_test)

"""#### **FEATURE IMPORTANCE VISUALIZATION**"""

# Function to get feature importance graph for XGBoost
def get_feature_importance(model):
    # Define the type of importance to be used ('weight', 'gain', or 'cover'
    importance_type = 'gain'

    # Retrieve feature importance scores from the XGBoost model
    importance = model.get_booster().get_score(importance_type=importance_type)

    # Sort features based on their importance scores
    sorted_importance = sorted(importance.items(), key=lambda x: x[1])
    features, scores = zip(*sorted_importance)

    # Create a horizontal bar plot for feature importance
    plt.figure(figsize=(10, 6))
    bars = plt.barh(range(len(features)), scores, align='center')
    plt.barh(range(len(features)), scores, align='center')
    plt.yticks(range(len(features)), features)
    plt.xlabel('Feature Importance')
    plt.title('XGBoost Feature Importance')

    # Add scores to the bars for better readability
    for bar, score in zip(bars, scores):
        plt.text(bar.get_width(), bar.get_y() + bar.get_height()/2, f'{score:.2f}',
                 va='center', ha='left', fontsize=10, color='black')
    # Displaying the plot
    plt.show()

# Call the function to get and display feature importance
# get_feature_importance(xgboost)